{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load everything we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, Callback, EarlyStopping\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our data: Features(x) and labels(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load npz file containing image arrays\n",
    "x_npz = np.load(\"x_Pneumothorax_balanced_128.npz\")\n",
    "x = x_npz['arr_0']\n",
    "# Load binary encoded labels for Lung Infiltrations: 0=disiese not found 1=disiese found\n",
    "y_npz = np.load(\"y_Pneumothorax_balanced_128.npz\")\n",
    "y = y_npz['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the number of deseas found in the dataset!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: not found, 1: found\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we want to create a mask to balance the samples for the two classes just uncomment the lines bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n = 4556\n",
    "#mask = np.hstack([np.random.choice(np.where(y == l)[0], n, replace=False)for l in np.unique(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = x[mask]\n",
    "#y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique, counts = np.unique(y, return_counts=True)\n",
    "#print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or if you want to use a weight class just run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y),y)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First split the data in two sets, 80% for training, 20% for Val/Test)\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(x,y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "# Second split the 20% into validation and test sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=1, stratify=y_valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is better to use the weights of the train samples\n",
    "class_weights_train = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "print(class_weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm using the categorical cross entropy as loss function,\n",
    "#so we need to convert our labels streming into a category list\n",
    "nb_categories = 2\n",
    "\n",
    "#use this to compare if label binarize is better than to_categorical\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train,nb_categories)\n",
    "y_test = np_utils.to_categorical(y_test,nb_categories)\n",
    "y_valtest = np_utils.to_categorical(y_valtest,nb_categories)\n",
    "y_val = np_utils.to_categorical(y_val,nb_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(X_train).shape)\n",
    "print(np.array(X_val).shape)\n",
    "print(np.array(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img_width, img_height = X_train.shape[1], X_train.shape[2]\n",
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "Number_of_conv_layers = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3),name=\"entrada\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_0\"))\n",
    "model.add(layers.Activation(\"relu\",name=\"activation_0\"))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2),name=\"max_pooling_0\"))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3),name=\"conv2D_1\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_1\"))\n",
    "model.add(layers.Activation(\"relu\",name=\"activation_1\"))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2),name=\"max_pooling_N1\"))\n",
    "\n",
    "######################################################\n",
    "model.add(layers.Conv2D(64, (3, 3),name=\"conv2D_N1\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_N1\"))\n",
    "model.add(layers.Activation(\"relu\",name=\"activation_N1\"))\n",
    "###########################################################\n",
    "model.add(layers.MaxPooling2D((2, 2),name=\"max_pooling_N2\"))\n",
    "######################################################\n",
    "model.add(layers.Conv2D(64, (3, 3),name=\"conv2D_N2\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_N2\"))\n",
    "model.add(layers.Activation(\"relu\",name=\"activation_N2\"))\n",
    "###########################################################\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2),name=\"max_pooling_1\"))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3),name=\"conv2D_2\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_2\"))\n",
    "model.add(layers.Activation(\"relu\",name=\"activation_2\"))\n",
    "\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2),name=\"max_pooling_2\"))\n",
    "\n",
    "model.add(layers.Flatten(name=\"achata\"))\n",
    "model.add(layers.Dropout(0.2,name=\"dropout_0\"))\n",
    "model.add(layers.Dense(64,name=\"dense_0\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_3\"))\n",
    "model.add(layers.Activation(\"relu\",name=\"activation_3\"))\n",
    "\n",
    "model.add(layers.Dense(2,name=\"classificator\"))\n",
    "model.add(layers.BatchNormalization(name=\"batch_norm_4\"))\n",
    "model.add(layers.Activation(\"sigmoid\",name=\"activation_4\"))\n",
    "#sparse_categorical_crossentropy\n",
    "#binary_crossentropy\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "    metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"5conv_test_2class.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255, horizontal_flip=True, rotation_range=30)\n",
    "valtest_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The default behavior of flow_from_directory is to shuffle the data; \n",
    "#this means that the predictions from predict generator will not correspond to the ground truth labels \n",
    "#which you get from test_generator.classes. So set shuffle = False\n",
    "\n",
    "train_generator = train_datagen.flow(np.array(X_train), y_train, batch_size=batch_size,shuffle=False)\n",
    "validation_generator = valtest_datagen.flow(np.array(X_val), y_val, batch_size=batch_size, shuffle=False)\n",
    "test_generator = valtest_datagen.flow(np.array(X_test), y_test, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs_layers_{}/{}\".format(time(),Number_of_conv_layers),histogram_freq=0,write_images=True, write_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights_balanced_{}_layers_{}.hdf5'.format(time(),Number_of_conv_layers), verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlierstop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    class_weight=class_weights_train,\n",
    "    callbacks=[tensorboard,checkpointer],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig(\"/home/felipe/Dropbox/ML_diagnostics/draft/Felipe_notes/fig/model_accuracy.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig(\"/home/felipe/Dropbox/ML_diagnostics/draft/Felipe_notes/fig/model_loss.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_balanced_1537784937.41_layers_5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dict_characters = { 1: 'Pneumothorax Observed', 0: 'No Pneumothorax Observed'}#['Infiltration Observed', 'No Infiltration Observed']\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',fontsize=20,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45,fontsize=17)\n",
    "    plt.yticks(tick_marks, classes,fontsize=17)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"black\", fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=20)\n",
    "    plt.xlabel('Predicted label',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=X_train\n",
    "b=y_train\n",
    "c=X_valtest\n",
    "d=y_valtest\n",
    "Y_pred = model.predict_generator(validation_generator,nb_validation_samples // batch_size+1)\n",
    "Y_pred_classes = np.argmax(Y_pred,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(validation_generator,nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.argmax(validation_generator.y,axis=1), Y_pred_classes, target_names=list(dict_characters.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(np.argmax(validation_generator.y, axis=1), Y_pred_classes)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=[10,8])\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(dict_characters.values()),\n",
    "                      title='Confusion matrix')\n",
    "#plt.savefig(\"/home/felipe/Dropbox/ML_diagnostics/draft/Felipe_notes/fig/confusion_matrix_Infiltration.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,8])\n",
    "plot_confusion_matrix(cnf_matrix, classes=dict_characters.values(), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.savefig(\"figs/norm_CM_balanced_2xtra.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr0, tpr0, thresholds0 = roc_curve(validation_generator.y[:,0], Y_pred[:,0])\n",
    "fpr1, tpr1, thresholds1 = roc_curve(validation_generator.y[:,1], Y_pred[:,1])\n",
    "roc_auc0 = auc(fpr0, tpr0)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "lw = 2\n",
    "plt.plot(fpr0, tpr0, color='darkorange',\n",
    "         lw=lw, label='ROC no findings (area = %0.2f)'%(roc_auc0))\n",
    "plt.plot(fpr1, tpr1, color='darkred',\n",
    "         lw=lw, label='ROC Pneumothorax (area = %0.2f)'%(roc_auc1))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('figs/ROC_2extra.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(np.argmax(validation_generator.y,axis=1), Y_pred_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC (area = %0.2f)'%(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "#plt.savefig('/home/felipe/Dropbox/ML_diagnostics/draft/Felipe_notes/fig/ROC_unweighted_avg.pdf')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision0, recall0, thresholds0 = precision_recall_curve(validation_generator.y[:,0], Y_pred[:,0])\n",
    "precision1, recall1, thresholds1 = precision_recall_curve(validation_generator.y[:,1], Y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision0 = average_precision_score(validation_generator.y[:,0], Y_pred[:,0])\n",
    "average_precision1 = average_precision_score(validation_generator.y[:,1], Y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,8])\n",
    "plt.step(recall0, precision0, color='b', alpha=0.2,\n",
    "         where='post',label='PR no findings (AP = %0.2f)'%(average_precision0))\n",
    "plt.fill_between(recall0, precision0, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "plt.step(recall1, precision1, color='y', alpha=0.8,\n",
    "         where='post',label='PR findings (AP = %0.2f)'%(average_precision1))\n",
    "plt.fill_between(recall1, precision1, step='post', alpha=0.8,\n",
    "                 color='y')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP0={0:0.2f}, AP1={1:0.2f}'.format(\n",
    "          average_precision0,average_precision1))\n",
    "plt.legend(loc=\"best\")\n",
    "#plt.savefig('/home/felipe/Dropbox/ML_diagnostics/draft/Felipe_notes/fig/PR_unweighted.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(np.argmax(validation_generator.y, axis=1), Y_pred_classes)\n",
    "average_precision = average_precision_score(np.argmax(validation_generator.y, axis=1), Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,8])\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "#plt.savefig('/home/felipe/Dropbox/ML_diagnostics/draft/Felipe_notes/fig/PR_unweighted_avg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
